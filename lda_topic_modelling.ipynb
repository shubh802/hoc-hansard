{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>LDA Topic Modelling</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ In this file we will perform the topic modelling of hansard data using Latent Dirichlet Allocation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshi\\anaconda3\\envs\\thesis\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from utils.utils import *\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from pylab import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshi\\anaconda3\\envs\\thesis\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "c:\\Users\\joshi\\anaconda3\\envs\\thesis\\lib\\site-packages\\gensim\\matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n",
      "c:\\Users\\joshi\\anaconda3\\envs\\thesis\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spaCy for Lemmatization\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA analysis of the data, deciding the topics based on the perplexity and coherence metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HOCLDATopic:\n",
    "\n",
    "    \"\"\"\n",
    "         A class used to perform topic modelling on the hansard data, testing the LDA model\n",
    "         and plotting the results.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df_head_dt_gp_21):\n",
    "        self.df_head_dt_gp_21 = df_head_dt_gp_21\n",
    "\n",
    "    ### LDA Analysis ###\n",
    "\n",
    "    def sent_to_words(self, sentences):\n",
    "        \"\"\" The function performs gensim preprocessing on the sentences\n",
    "            sentences - data \"\"\"\n",
    "        for sentence in sentences:\n",
    "            # deacc=True removes punctuations\n",
    "            yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "            \n",
    "    def lemmatization(self, texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "        \"\"\" The function lemmatizes the words using spacy\n",
    "            text - data \"\"\"\n",
    "\n",
    "        texts_out = []\n",
    "        # Loading the spacy module\n",
    "        nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "        for sent in texts:\n",
    "            doc = nlp(\" \".join(sent)) \n",
    "            texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "        return texts_out\n",
    "\n",
    "    def get_lda_data(self, df):\n",
    "        \"\"\" The function creates data for lda analysis and returns the corpus of words\n",
    "            df - Datframe \"\"\"\n",
    "\n",
    "        data = df.speech_processed.values.tolist()\n",
    "        data_words = list(self.sent_to_words(data))\n",
    "\n",
    "        data_lemmatized = self.lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']);\n",
    "\n",
    "        # Create Dictionary\n",
    "        id2word = corpora.Dictionary(data_lemmatized)\n",
    "        # Create Corpus\n",
    "        texts = data_lemmatized\n",
    "        # Term Document Frequency\n",
    "        corpus = [id2word.doc2bow(text) for text in texts]\n",
    "        return id2word, corpus, data_lemmatized\n",
    "\n",
    "    def get_lda_model(self, id2word, corpus, topics):\n",
    "        \"\"\" The function creates lda returns it\n",
    "            id2word - dictionary\n",
    "            corpus - corpus of words\n",
    "            topics - no of topics \"\"\"\n",
    "\n",
    "        # Build LDA model\n",
    "        lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=topics)\n",
    "        doc_lda = lda_model[corpus]\n",
    "        # Return LDA model\n",
    "        return lda_model\n",
    "\n",
    "    def test_lda_model(self, corpus, id2word, lda_model, data_lemmatized):\n",
    "        \"\"\" The function test the lda model using perpexlity and cohesion\n",
    "            id2word - dictionary\n",
    "            corpus - corpus of words \n",
    "            lda_model - LDA model\"\"\"\n",
    "        perp=[]\n",
    "        cohe=[]\n",
    "        for k in range(2,20):\n",
    "            lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                                    id2word=id2word,\n",
    "                                                    num_topics=k)\n",
    "            perp.append(lda_model.log_perplexity(corpus))\n",
    "            coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "            cohe.append(coherence_model_lda.get_coherence())\n",
    "\n",
    "        return perp, cohe\n",
    "\n",
    "    def plot_lda_test(self, perp, cohe):\n",
    "        \"\"\" The function plots the perplexity and cohesion of lda model\n",
    "            id2word - dictionary\n",
    "            corpus - corpus of words \n",
    "            lda_model - LDA model\"\"\"\n",
    "\n",
    "        rcParams['figure.figsize'] = 12, 8\n",
    "        plt.plot(range(2,20),perp,'r-o')\n",
    "\n",
    "        # Title of the plot\n",
    "        plt.title(\"Perpexility in Topics\", fontsize=20)\n",
    "        # Labels of the plot\n",
    "        plt.xlabel(\"Topics\")\n",
    "        plt.ylabel(\"Perpexility\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(range(2,20),cohe,'g-o')\n",
    "        # Title of the Coherence plot\n",
    "        plt.title(\"Coherence in Topics\", fontsize=20)\n",
    "        plt.xlabel(\"Topics\", fontsize=12)\n",
    "        plt.ylabel(\"Coherence\",fontsize=12)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334928be5ed23319e5e6550927c5d4f3c3b4919c511fd9b77eaf79aad6ef04de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
