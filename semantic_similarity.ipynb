{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Semantic Similarity of Speeches</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ In this file we will look for the semantic similarity of the speeches based on the Document Embedding via Cr5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from warnings import filterwarnings\n",
    "from pylab import rcParams\n",
    "filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "filterwarnings(action='ignore', category=FutureWarning)\n",
    "from utils.utils import *\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshi\\anaconda3\\envs\\thesis\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./models/Cr5-master/src\")\n",
    "\n",
    "from gensim.utils import tokenize\n",
    "from cr5 import Cr5_Model\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HOCSemanticSimilarity:\n",
    "    \"\"\"\n",
    "         A class used to create the custom topic modelling by using document embeddings via Cr5 model,\n",
    "         then reducing the embeddding via UMAP and then clustering using KMeans to find the topics.\n",
    "    \"\"\"\n",
    "\n",
    "    base_path = r'./assets/images/'\n",
    "    def __init__(self, df_head_dt_gp_21, df_head_dt_gp_20):\n",
    "        \n",
    "        self.df_head_dt_gp_21 = df_head_dt_gp_21\n",
    "        self.df_head_dt_gp_20 = df_head_dt_gp_20\n",
    "\n",
    "\n",
    "    def get_model(self, path):\n",
    "        \"\"\" The function returns the Cr5 model\n",
    "            path - path to the model\n",
    "        \"\"\"\n",
    "        # Load the model\n",
    "        model = Cr5_Model(path,'joint_28')\n",
    "        # Model for en language\n",
    "        model.load_langs(['en'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_cr5_embeddings(self, df, model):\n",
    "        \"\"\" The function returns the Cr5 emdeddings\n",
    "            df - Dataframe\n",
    "            model - model\n",
    "        \"\"\"\n",
    "\n",
    "        token_ = [list(tokenize(speech)) for speech in df.speech_processed]\n",
    "        # Calculate the embeddings for the speeches\n",
    "        embeddings = [model.get_document_embedding(doc,'en') for doc in token_ ]\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "    def get_similarity_data(self, common_heading, model):\n",
    "        \"\"\" The function calculates the pairwise cosine similarity of Cr5 emdeddings for all the common headings\n",
    "            and returns the similarity data along with the median value of similarity score for each heading       \n",
    "            common_heading - List of common headings\n",
    "            model - Cr5 model\n",
    "        \"\"\"\n",
    "\n",
    "        similarities = []\n",
    "        median_dict = {}\n",
    "        for heading in common_heading:\n",
    "            # Get the speech with common heading from the dataframe\n",
    "            df_common_21 = get_speech_by_heading(self.df_head_dt_gp_21, heading)\n",
    "            df_common_20 = get_speech_by_heading(self.df_head_dt_gp_20, heading)\n",
    "\n",
    "            # Get the Cr5 embeddings for the speeches\n",
    "            common_embedding21 = self.get_cr5_embeddings(df_common_21, model)\n",
    "            common_embedding20 = self.get_cr5_embeddings(df_common_20, model)\n",
    "\n",
    "            # Calculate the pairwise cosine similarity of Cr5 emdeddings\n",
    "            similar_ = cosine_similarity(common_embedding21, common_embedding20)\n",
    "            data = [d for d in similar_.T]\n",
    "            # Calculate the median value of similarity score for each heading\n",
    "            median_dict[heading] = np.median(data)\n",
    "            similarities.append(data)\n",
    "            \n",
    "        return similarities, median_dict\n",
    "\n",
    "    def create_df(self, data, common_heading):\n",
    "        \"\"\" The function creates a dataframe of the similarity score and returns the dataframe\n",
    "            data - Similarity Score data     \n",
    "            common_heading - List of common headings\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.DataFrame(data=data, columns = [\"Similarity Score\"], index = common_heading)\n",
    "        df['Heading'] = common_heading\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def plot_similarity_data(self, df, semantic_dict, name):\n",
    "        \"\"\" The function plots Violin graph for the top and the least semantically similarity heading\n",
    "            df - Dataframe \n",
    "            semantic_dict - Dictionary of semantic similarity  \n",
    "            name - text\n",
    "        \"\"\"\n",
    "\n",
    "        rcParams['figure.figsize'] = 8, 6\n",
    "\n",
    "        fig = plt.figure() \n",
    "        ax = fig.add_subplot(111)   \n",
    "\n",
    "        # Plot the violin plot\n",
    "        sns.violinplot( data=[data for data in df['Similarity Score'].values])\n",
    "        ax.set_xticklabels(list(semantic_dict.keys()))\n",
    "\n",
    "        # Add xticks and labels \n",
    "        plt.xticks(rotation=20, ha='center')\n",
    "        plt.xlabel(\"Speeches in 2020\",  fontsize=15)\n",
    "        plt.ylabel(\"Similarity Score with Speeches in 2021\", fontsize=15)\n",
    "\n",
    "        text = \"Least\" if name == 'least_semantic_change' else \"Top\"\n",
    "        plt.title(f\"{text} Similar Speeches in 2020 and 2021\", fontsize=25)\n",
    "        # Save the plot\n",
    "        plt.savefig(HOCSemanticSimilarity.base_path+name+'.png')\n",
    "        plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334928be5ed23319e5e6550927c5d4f3c3b4919c511fd9b77eaf79aad6ef04de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
